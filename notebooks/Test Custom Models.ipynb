{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Overview<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Load-the-Data\" data-toc-modified-id=\"Load-the-Data-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span>Load the Data</a></span></li><li><span><a href=\"#Create-Model\" data-toc-modified-id=\"Create-Model-0.2\"><span class=\"toc-item-num\">0.2&nbsp;&nbsp;</span>Create Model</a></span></li><li><span><a href=\"#Compile-Model\" data-toc-modified-id=\"Compile-Model-0.3\"><span class=\"toc-item-num\">0.3&nbsp;&nbsp;</span>Compile Model</a></span></li><li><span><a href=\"#Fit-Model\" data-toc-modified-id=\"Fit-Model-0.4\"><span class=\"toc-item-num\">0.4&nbsp;&nbsp;</span>Fit Model</a></span></li></ul></li><li><span><a href=\"#Terminal\" data-toc-modified-id=\"Terminal-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Terminal</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from time import sleep\n",
    "from keras import backend as K\n",
    "from keras.models import Model \n",
    "from keras.models import Sequential as SequentialModel\n",
    "from keras.layers import Dense, Conv1D, LSTM, Dropout, Embedding, Layer, Input, Flatten, concatenate as Concatenate, Lambda\n",
    "from keras.callbacks import Callback\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer as KerasTokenizer\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "sys.path.insert(0, '../ct')\n",
    "\n",
    "import load\n",
    "from preprocess import preprocess\n",
    "from preprocess import Tokenizer\n",
    "from preprocess.preprocess import separator_samples\n",
    "\n",
    "from model.layers import LayerNormalization\n",
    "from model.layers import ContentBasedAttention_CT\n",
    "from model.layers import ScaledDotProductAttention\n",
    "from model.layers import MultiHeadAttention\n",
    "\n",
    "from model import CompressiveTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_pickle('../data/processed/spooky-author/train.pkl')\n",
    "\n",
    "x_train = np.array(train_data.x.tolist())\n",
    "y_train = np.array(train_data.y.tolist())\n",
    "\n",
    "_x_train = np.zeros((x_train.shape[0], 128))  # samples, d_model\n",
    "_x_train[:,:x_train.shape[1]] = x_train\n",
    "x_train = _x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking <tf.Variable 'memory:0' shape=(1, 512, 256) dtype=float32, numpy=\n",
      "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)> memory\n",
      "tracking <tf.Variable 'compressed_memory:0' shape=(1, 512, 256) dtype=float32, numpy=\n",
      "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)> compressed_memory\n",
      "Tensor(\"concatenate_52/concat:0\", shape=(None, 1024, 256), dtype=float32)\n",
      "Tensor(\"embedding_55/embedding_lookup/Identity_1:0\", shape=(None, 128, 256), dtype=float32)\n",
      "Tensor(\"concatenate_52/concat:0\", shape=(None, 1024, 256), dtype=float32)\n",
      "Tensor(\"concatenate_52/concat:0\", shape=(None, 1024, 256), dtype=float32)\n",
      "Tensor(\"scaled_dot_product_attention_99/Reshape_2:0\", shape=(None, 128, 256), dtype=float32)\n",
      "Tensor(\"scaled_dot_product_attention_99/Reshape_5:0\", shape=(None, 1024, 256), dtype=float32)\n",
      "Tensor(\"scaled_dot_product_attention_99/Reshape_8:0\", shape=(None, 1024, 256), dtype=float32)\n",
      "Scaled Dot Product Attention:\n",
      "    q.shape=(None, 128, 256),\n",
      "    k.shape=(None, 1024, 256),\n",
      "    v.shape=(None, 1024, 256)\n",
      "    k_T.shape=(None, 256, 1024)\n",
      "    y.shape=(None, 128, 256)\n",
      "#### COMPUTE OUTPUT SHAPE ####\n",
      "(None, 128, 256)\n",
      "Tensor(\"embedding_55/embedding_lookup/Identity_1:0\", shape=(None, 128, 256), dtype=float32)\n",
      "Tensor(\"concatenate_52/concat:0\", shape=(None, 1024, 256), dtype=float32)\n",
      "Tensor(\"concatenate_52/concat:0\", shape=(None, 1024, 256), dtype=float32)\n",
      "Tensor(\"scaled_dot_product_attention_100/Reshape_2:0\", shape=(None, 128, 256), dtype=float32)\n",
      "Tensor(\"scaled_dot_product_attention_100/Reshape_5:0\", shape=(None, 1024, 256), dtype=float32)\n",
      "Tensor(\"scaled_dot_product_attention_100/Reshape_8:0\", shape=(None, 1024, 256), dtype=float32)\n",
      "Scaled Dot Product Attention:\n",
      "    q.shape=(None, 128, 256),\n",
      "    k.shape=(None, 1024, 256),\n",
      "    v.shape=(None, 1024, 256)\n",
      "    k_T.shape=(None, 256, 1024)\n",
      "    y.shape=(None, 128, 256)\n",
      "#### COMPUTE OUTPUT SHAPE ####\n",
      "(None, 128, 256)\n",
      "(1, 512, 256)\n",
      "(1, 512, 256)\n"
     ]
    }
   ],
   "source": [
    "d_model = 256\n",
    "sequence_length = 128\n",
    "\n",
    "model = CompressiveTransformer(d_model=d_model, sequence_length=sequence_length, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CompressiveTransformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "x (InputLayer)                  (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "memory (InputLayer)             (None, 512, 256)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "compressed_memory (InputLayer)  (None, 512, 256)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_55 (Embedding)        (None, 128, 256)     5120000     x[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_52 (Concatenate)    (None, 1024, 256)    0           memory[0][0]                     \n",
      "                                                                 compressed_memory[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "scaled_dot_product_attention_99 (None, 128, 256)     196608      embedding_55[0][0]               \n",
      "                                                                 concatenate_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scaled_dot_product_attention_10 (None, 128, 256)     196608      embedding_55[0][0]               \n",
      "                                                                 concatenate_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multihead_attention_L0 (MultiHe (None, 128, 256)     131072      scaled_dot_product_attention_99[0\n",
      "                                                                 scaled_dot_product_attention_100[\n",
      "__________________________________________________________________________________________________\n",
      "mha_skip_L0 (Add)               (None, 128, 256)     0           embedding_55[0][0]               \n",
      "                                                                 multihead_attention_L0[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mha_layer_norm_L0 (LayerNormali (None, 128, 256)     0           mha_skip_L0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "mlp_hidden_0_L0 (Dense)         (None, 128, 256)     65792       mha_layer_norm_L0[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "mlp_L0 (Dense)                  (None, 128, 256)     65792       mlp_hidden_0_L0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "mlp_skip_L0 (Add)               (None, 128, 256)     0           mlp_L0[0][0]                     \n",
      "                                                                 mha_layer_norm_L0[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "mlp_layer_norm_L0 (LayerNormali (None, 128, 256)     0           mlp_skip_L0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "AttentionReconstruction (Attent (1, 170, 128)        98432                                        \n",
      "==================================================================================================\n",
      "Total params: 5,874,304\n",
      "Trainable params: 5,874,304\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',\n",
    "              loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19579, 128)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected mlp_layer_norm_L0 to have 3 dimensions, but got array with shape (1, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-152-ed7733035218>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     model.train_on_batch(x_batch,\n\u001b[1;32m----> 6\u001b[1;33m                          y_batch)\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\CompressiveTransformer\\ct\\model\\model.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m    228\u001b[0m                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m                                \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m                                reset_metrics=reset_metrics)\n\u001b[0m\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_h\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1506\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1507\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1508\u001b[1;33m             class_weight=class_weight)\n\u001b[0m\u001b[0;32m   1509\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1510\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    619\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 621\u001b[1;33m                 exception_prefix='target')\n\u001b[0m\u001b[0;32m    622\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m             \u001b[1;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    133\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    136\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected mlp_layer_norm_L0 to have 3 dimensions, but got array with shape (1, 3)"
     ]
    }
   ],
   "source": [
    "for batch in range(0, len(x_train), 1):\n",
    "    x_batch = x_train[batch:batch+1, :]\n",
    "    y_batch = y_train[batch:batch+1]\n",
    "    \n",
    "    model.train_on_batch(x_batch,\n",
    "                         y_batch)\n",
    "    break\n",
    "\n",
    "\n",
    "# model.fit(x_train, \n",
    "#           y_train,\n",
    "#           epochs=8,\n",
    "#           batch_size=32,\n",
    "#           validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = K.variable([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([i for i in range(200)]).reshape((10, 20))\n",
    "b = np.array([i*100 for i in range(100)]).reshape((5, 20))\n",
    "\n",
    "a = K.variable(a)\n",
    "b = K.variable(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K.concatenate([a,b], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 15, 20)\n"
     ]
    }
   ],
   "source": [
    "a = K.zeros((2, 5, 20))\n",
    "b = K.zeros((2, 10, 20))\n",
    "\n",
    "c = K.concatenate([a, b], axis=1)\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 0, 20), dtype=float32, numpy=array([], shape=(2, 0, 20), dtype=float32)>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:, 5:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "units=100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[-1.2232091 , -1.2170624 , -1.2109156 , -1.2047688 ,\n",
       "         -1.1986221 , -1.1924753 , -1.1863285 , -1.1801817 ,\n",
       "         -1.174035  , -1.1678882 , -1.1617414 , -1.1555946 ,\n",
       "         -1.1494478 , -1.143301  , -1.1371542 , -1.1310074 ,\n",
       "         -1.1248606 , -1.1187139 , -1.1125672 , -1.1064204 ],\n",
       "        [-1.1002736 , -1.0941268 , -1.08798   , -1.0818332 ,\n",
       "         -1.0756865 , -1.0695397 , -1.0633929 , -1.0572461 ,\n",
       "         -1.0510993 , -1.0449525 , -1.0388057 , -1.032659  ,\n",
       "         -1.0265123 , -1.0203655 , -1.0142187 , -1.0080719 ,\n",
       "         -1.0019251 , -0.9957783 , -0.98963153, -0.98348475],\n",
       "        [-0.97733796, -0.9711912 , -0.96504444, -0.95889765,\n",
       "         -0.95275086, -0.9466041 , -0.9404573 , -0.9343105 ,\n",
       "         -0.92816377, -0.922017  , -0.9158702 , -0.9097234 ,\n",
       "         -0.9035766 , -0.8974298 , -0.89128304, -0.8851363 ,\n",
       "         -0.8789895 , -0.8728427 , -0.86669594, -0.86054915],\n",
       "        [-0.85440236, -0.84825563, -0.84210885, -0.83596206,\n",
       "         -0.82981527, -0.8236685 , -0.8175217 , -0.8113749 ,\n",
       "         -0.8052282 , -0.7990814 , -0.7929346 , -0.7867878 ,\n",
       "         -0.780641  , -0.77449423, -0.76834744, -0.7622007 ,\n",
       "         -0.7560539 , -0.74990714, -0.74376035, -0.73761356],\n",
       "        [-0.73146677, -0.72532   , -0.71917325, -0.71302646,\n",
       "         -0.7068797 , -0.7007329 , -0.6945861 , -0.6884393 ,\n",
       "         -0.6822926 , -0.6761458 , -0.669999  , -0.6638522 ,\n",
       "         -0.6577054 , -0.65155864, -0.64541185, -0.6392651 ,\n",
       "         -0.63311833, -0.62697154, -0.62082475, -0.61467797]],\n",
       "\n",
       "       [[-0.6085312 , -0.6023844 , -0.59623766, -0.5900909 ,\n",
       "         -0.5839441 , -0.5777973 , -0.5716505 , -0.5655037 ,\n",
       "         -0.5593569 , -0.5532102 , -0.5470634 , -0.5409166 ,\n",
       "         -0.53476983, -0.52862304, -0.52247626, -0.5163295 ,\n",
       "         -0.51018274, -0.50403595, -0.49788916, -0.49174237],\n",
       "        [-0.4855956 , -0.47944883, -0.47330204, -0.46715525,\n",
       "         -0.4610085 , -0.4548617 , -0.4487149 , -0.44256815,\n",
       "         -0.43642136, -0.43027458, -0.42412782, -0.41798103,\n",
       "         -0.41183424, -0.40568745, -0.3995407 , -0.3933939 ,\n",
       "         -0.38724712, -0.38110036, -0.37495357, -0.36880678],\n",
       "        [-0.36266   , -0.35651323, -0.35036644, -0.34421965,\n",
       "         -0.3380729 , -0.3319261 , -0.32577932, -0.31963256,\n",
       "         -0.31348577, -0.30733898, -0.3011922 , -0.29504544,\n",
       "         -0.28889865, -0.28275186, -0.2766051 , -0.2704583 ,\n",
       "         -0.26431152, -0.25816476, -0.25201797, -0.24587119],\n",
       "        [-0.23972441, -0.23357762, -0.22743085, -0.22128408,\n",
       "         -0.21513729, -0.20899051, -0.20284373, -0.19669695,\n",
       "         -0.19055018, -0.18440339, -0.17825662, -0.17210983,\n",
       "         -0.16596305, -0.15981628, -0.15366949, -0.14752272,\n",
       "         -0.14137593, -0.13522916, -0.12908238, -0.12293559],\n",
       "        [-0.11678881, -0.11064204, -0.10449526, -0.09834848,\n",
       "         -0.09220169, -0.08605491, -0.07990814, -0.07376136,\n",
       "         -0.06761458, -0.0614678 , -0.05532102, -0.04917424,\n",
       "         -0.04302746, -0.03688068, -0.0307339 , -0.02458712,\n",
       "         -0.01844034, -0.01229356, -0.00614678,  0.        ]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = K.variable(np.array([i for i in range(200)]).reshape((2, 5, 20)))\n",
    "\n",
    "def call(x, units=None, gain=None, bias=None):\n",
    "    if units is None:\n",
    "        units = np.prod(x.shape[1:])\n",
    "        print(f'units={units}')\n",
    "    \n",
    "    mean = K.sum(x) / units\n",
    "    std_dev = K.sqrt(K.sum(K.square(x - mean)) / units)\n",
    "\n",
    "    y = (x - mean) / std_dev\n",
    "    if gain:\n",
    "        y *= gain\n",
    "    if bias:\n",
    "        y += bias\n",
    "    return y\n",
    "\n",
    "K.eval(call(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Overview",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
