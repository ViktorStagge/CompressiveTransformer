{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Compressive-Transformer\" data-toc-modified-id=\"Compressive-Transformer-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Compressive Transformer</a></span><ul class=\"toc-item\"><li><span><a href=\"#Options:\" data-toc-modified-id=\"Options:-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Options:</a></span></li><li><span><a href=\"#setup\" data-toc-modified-id=\"setup-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>setup</a></span></li><li><span><a href=\"#Create-Model\" data-toc-modified-id=\"Create-Model-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Create Model</a></span></li><li><span><a href=\"#Model-summary\" data-toc-modified-id=\"Model-summary-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Model summary</a></span></li><li><span><a href=\"#Create-train/test-data-generators\" data-toc-modified-id=\"Create-train/test-data-generators-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Create train/test data-generators</a></span></li><li><span><a href=\"#Create-addtional-Run-Configurations\" data-toc-modified-id=\"Create-addtional-Run-Configurations-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Create addtional Run Configurations</a></span></li><li><span><a href=\"#Train\" data-toc-modified-id=\"Train-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>Train</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from time import sleep, time\n",
    "from keras import backend as K\n",
    "from keras.models import Model \n",
    "from keras.models import Sequential as SequentialModel\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense, Conv1D, LSTM, Dropout, Embedding, Layer, Input, Flatten, concatenate as Concatenate, Lambda, Add\n",
    "from keras.callbacks import Callback\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from time import sleep, time\n",
    "from keras import backend as K\n",
    "from keras.models import Model \n",
    "from keras.models import Sequential as SequentialModel\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense, Conv1D, LSTM, Dropout, Embedding, Layer, Input, Flatten, concatenate as Concatenate, Lambda, Add\n",
    "from keras.callbacks import Callback\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer as KerasTokenizer\n",
    "from tqdm.notebook import tqdm\n",
    "from sometimer import timer, time_this_method\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "sys.path.insert(0, '../ct')\n",
    "\n",
    "import load\n",
    "from preprocess import preprocess\n",
    "from preprocess import Tokenizer\n",
    "from preprocess.preprocess import separator_samples\n",
    "\n",
    "from model.layers import LayerNormalization\n",
    "from model.layers import ContentBasedAttention_CT\n",
    "from model.layers import ScaledDotProductAttention\n",
    "from model.layers import MultiHeadAttention\n",
    "from model.layers import content_based_attention\n",
    "\n",
    "from model import CompressiveTransformer\n",
    "from model import AttentionReconstruction\n",
    "\n",
    "from model.callbacks import ClearCompressedMemory, WriteLogsToFile\n",
    "from train.generators import next_token_batch_generator\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer as KerasTokenizer\n",
    "from tqdm.notebook import tqdm\n",
    "from sometimer import timer, time_this_method\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "sys.path.insert(0, '../ct')\n",
    "\n",
    "import load\n",
    "from preprocess import preprocess\n",
    "from preprocess import Tokenizer\n",
    "from preprocess.preprocess import separator_samples\n",
    "\n",
    "from model.layers import LayerNormalization\n",
    "from model.layers import ContentBasedAttention_CT\n",
    "from model.layers import ScaledDotProductAttention\n",
    "from model.layers import MultiHeadAttention\n",
    "from model.layers import content_based_attention\n",
    "\n",
    "from model import CompressiveTransformer\n",
    "from model import AttentionReconstruction\n",
    "\n",
    "from model.callbacks import ClearCompressedMemory, WriteLogsToFile\n",
    "from train.generators import next_token_batch_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compressive Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=2\n",
    "batch_size=128\n",
    "d_layers=2\n",
    "sequence_length=128\n",
    "d_model=128\n",
    "vocab_size=1024\n",
    "steps_per_validation=10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape \n",
    "def _preprocess(series, batch_size, output_path=None, use_existing=True):\n",
    "    processed = np.array([ids for english_ids in series for ids in english_ids])\n",
    "    return processed\n",
    "    \n",
    "    \n",
    "    \n",
    "#     if use_existing and os.path.exists(output_path):\n",
    "#         with open(output_path, 'rb') as file:\n",
    "#             processed = np.load(file)\n",
    "#         return processed\n",
    "\n",
    "#     train = [list() for _ in range(batch_size)] \n",
    "#     for i, t in enumerate(series):\n",
    "#         train[i % batch_size].extend(t)\n",
    "\n",
    "#     sample_length = min(len(t) for t in train)\n",
    "#     train = [t[:sample_length] for t in train]\n",
    "#     train = np.array(train)\n",
    "\n",
    "#     if output_path is not None:\n",
    "#         with open(output_path, 'wb') as file:\n",
    "#             np.save(file, train)\n",
    "\n",
    "#     return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_pickle('../data/wma-en-de/processed/train-en.pkl')\n",
    "val_data = pd.read_pickle('../data/wma-en-de/processed/val-en.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = _preprocess(train_data.english_ids,\n",
    "                    batch_size=batch_size,\n",
    "#                     output_path='../data/wma-en-de/processed/train.np', \n",
    "                    use_existing=False)\n",
    "val = _preprocess(val_data.english_ids, \n",
    "                  batch_size=batch_size,\n",
    "#                   output_path='../data/wma-en-de/processed/val.np', \n",
    "                  use_existing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_steps=len(train)  # epoch_steps=train.shape[1]\n",
    "validation_steps=len(val)  # validation_steps=val.shape[1]\n",
    "steps_per_epoch=epoch_steps//sequence_length\n",
    "steps_per_validation= steps_per_validation or validation_steps//sequence_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = CompressiveTransformer(d_layers=d_layers,\n",
    "                            sequence_length=sequence_length, \n",
    "                            d_model=d_model,\n",
    "                            memory_size=256,\n",
    "                            compressed_memory_size=256,\n",
    "                            d_k=16, \n",
    "                            d_heads=2, \n",
    "                            output_size=vocab_size,\n",
    "                            batch_size=batch_size,\n",
    "                            vocab_size=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function AttentionReconstruction.attention_reconstruction_loss.<locals>._attention_reconstruction_loss at 0x7f26fc240b00>\n",
      "   calculating loss...\n",
      "<function AttentionReconstruction.attention_reconstruction_loss.<locals>._attention_reconstruction_loss at 0x7f26fc24a8c0>\n",
      "   calculating loss...\n"
     ]
    }
   ],
   "source": [
    "ct.compile(optimizer='Adam',\n",
    "           loss='categorical_crossentropy',\n",
    "           metrics=['accuracy']\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CompressiveTransformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "x (InputLayer)                  (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "compressed_memory (InputLayer)  (None, 2, 256, 128)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "memory (InputLayer)             (None, 2, 256, 128)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "h_L0 (Embedding)                (None, 128, 128)     131072      x[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "select_compressed_memory_L0 (La (None, 256, 128)     0           compressed_memory[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "select_memory_L0 (Lambda)       (None, 256, 128)     0           memory[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "h_tilde_L0 (Concatenate)        (None, 640, 128)     0           select_compressed_memory_L0[0][0]\n",
      "                                                                 select_memory_L0[0][0]           \n",
      "                                                                 h_L0[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "scaled_dot_product_attention_1  (None, 128, 128)     20480       h_L0[0][0]                       \n",
      "                                                                 h_tilde_L0[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "scaled_dot_product_attention_2  (None, 128, 128)     20480       h_L0[0][0]                       \n",
      "                                                                 h_tilde_L0[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multihead_attention_L0 (MultiHe (None, 128, 128)     32768       scaled_dot_product_attention_1[0]\n",
      "                                                                 scaled_dot_product_attention_2[0]\n",
      "__________________________________________________________________________________________________\n",
      "mha_skip_L0 (Add)               (None, 128, 128)     0           h_L0[0][0]                       \n",
      "                                                                 multihead_attention_L0[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mha_layer_norm_L0 (LayerNormali (None, 128, 128)     32768       mha_skip_L0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "mlp_hidden_0_L0 (Dense)         (None, 128, 128)     16512       mha_layer_norm_L0[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "mlp_no_activation_L0 (Dense)    (None, 128, 128)     16512       mlp_hidden_0_L0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "mlp_skip_L0 (Add)               (None, 128, 128)     0           mlp_no_activation_L0[0][0]       \n",
      "                                                                 mha_layer_norm_L0[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "h_L1 (LayerNormalization)       (None, 128, 128)     32768       mlp_skip_L0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "select_compressed_memory_L1 (La (None, 256, 128)     0           compressed_memory[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "select_memory_L1 (Lambda)       (None, 256, 128)     0           memory[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "h_tilde_L1 (Concatenate)        (None, 640, 128)     0           select_compressed_memory_L1[0][0]\n",
      "                                                                 select_memory_L1[0][0]           \n",
      "                                                                 h_L1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "scaled_dot_product_attention_3  (None, 128, 128)     20480       h_L1[0][0]                       \n",
      "                                                                 h_tilde_L1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "scaled_dot_product_attention_4  (None, 128, 128)     20480       h_L1[0][0]                       \n",
      "                                                                 h_tilde_L1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multihead_attention_L1 (MultiHe (None, 128, 128)     32768       scaled_dot_product_attention_3[0]\n",
      "                                                                 scaled_dot_product_attention_4[0]\n",
      "__________________________________________________________________________________________________\n",
      "mha_skip_L1 (Add)               (None, 128, 128)     0           h_L1[0][0]                       \n",
      "                                                                 multihead_attention_L1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mha_layer_norm_L1 (LayerNormali (None, 128, 128)     32768       mha_skip_L1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "mlp_hidden_0_L1 (Dense)         (None, 128, 128)     16512       mha_layer_norm_L1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "mlp_no_activation_L1 (Dense)    (None, 128, 128)     16512       mlp_hidden_0_L1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "mlp_skip_L1 (Add)               (None, 128, 128)     0           mlp_no_activation_L1[0][0]       \n",
      "                                                                 mha_layer_norm_L1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "h_L2 (LayerNormalization)       (None, 128, 128)     32768       mlp_skip_L1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "output (ReverseEmbedding)       (None, 1024)         131072      h_L2[0][0]                       \n",
      "==================================================================================================\n",
      "Total params: 606,720\n",
      "Trainable params: 475,648\n",
      "Non-trainable params: 131,072\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ct.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train/test data-generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = next_token_batch_generator(ct=ct,\n",
    "                                       epochs=epochs, \n",
    "                                       data=train,\n",
    "                                       data_path=None,\n",
    "                                       epoch_steps=epoch_steps, \n",
    "                                       sequence_length=sequence_length, \n",
    "                                       batch_size=sequence_length,\n",
    "                                       stride=1,\n",
    "                                       vocab_size=vocab_size)\n",
    "validation_generator = next_token_batch_generator(ct=ct,\n",
    "                                                  epochs=epochs, \n",
    "                                                  data=val,\n",
    "                                                  data_path=None,\n",
    "                                                  epoch_steps=validation_steps, \n",
    "                                                  sequence_length=sequence_length, \n",
    "                                                  batch_size=sequence_length,\n",
    "                                                  stride=1, \n",
    "                                                  vocab_size=vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create addtional Run Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [ClearCompressedMemory(),\n",
    "             WriteLogsToFile(filepath='training-logs/ct.txt', overwrite_old_file=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vs/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "  97111/1626084 [>.............................] - ETA: 128:12:16 - loss: 5.7941 - accuracy: 0.0216"
     ]
    }
   ],
   "source": [
    "ct.fit_generator(generator(), \n",
    "                 steps_per_epoch=steps_per_epoch,\n",
    "                 epochs=epochs,\n",
    "                 callbacks=callbacks,\n",
    "                 validation_data=validation_generator(),\n",
    "                 validation_steps=steps_per_validation,\n",
    "                 shuffle=False\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- multiple layers\n",
    "- larger embedding\n",
    "- longer dataset\n",
    "- relative embedding\n",
    "- attention reconstruction loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
