{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Compressive-Transformer\" data-toc-modified-id=\"Compressive-Transformer-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Compressive Transformer</a></span><ul class=\"toc-item\"><li><span><a href=\"#Options:\" data-toc-modified-id=\"Options:-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Options:</a></span></li><li><span><a href=\"#setup\" data-toc-modified-id=\"setup-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>setup</a></span></li><li><span><a href=\"#Create-Model\" data-toc-modified-id=\"Create-Model-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Create Model</a></span></li><li><span><a href=\"#Model-summary\" data-toc-modified-id=\"Model-summary-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Model summary</a></span></li><li><span><a href=\"#Create-train/test-data-generators\" data-toc-modified-id=\"Create-train/test-data-generators-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Create train/test data-generators</a></span></li><li><span><a href=\"#Create-addtional-Run-Configurations\" data-toc-modified-id=\"Create-addtional-Run-Configurations-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Create addtional Run Configurations</a></span></li><li><span><a href=\"#Train\" data-toc-modified-id=\"Train-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>Train</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from time import sleep, time\n",
    "from keras import backend as K\n",
    "from keras.models import Model \n",
    "from keras.models import Sequential as SequentialModel\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense, Conv1D, LSTM, Dropout, Embedding, Layer, Input, Flatten, concatenate as Concatenate, Lambda, Add\n",
    "from keras.callbacks import Callback\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from time import sleep, time\n",
    "from keras import backend as K\n",
    "from keras.models import Model \n",
    "from keras.models import Sequential as SequentialModel\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense, Conv1D, LSTM, Dropout, Embedding, Layer, Input, Flatten, concatenate as Concatenate, Lambda, Add\n",
    "from keras.callbacks import Callback\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer as KerasTokenizer\n",
    "from tqdm.notebook import tqdm\n",
    "from sometimer import timer, time_this_method\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "sys.path.insert(0, '../ct')\n",
    "\n",
    "import load\n",
    "from preprocess import preprocess\n",
    "from preprocess import Tokenizer\n",
    "from preprocess.preprocess import separator_samples\n",
    "\n",
    "from model.layers import LayerNormalization\n",
    "from model.layers import ContentBasedAttention_CT\n",
    "from model.layers import ScaledDotProductAttention\n",
    "from model.layers import MultiHeadAttention\n",
    "from model.layers import content_based_attention\n",
    "\n",
    "from model import CompressiveTransformer\n",
    "from model import AttentionReconstruction\n",
    "\n",
    "from model.callbacks import ClearCompressedMemory, WriteLogsToFile\n",
    "from train.generators import next_token_batch_generator\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer as KerasTokenizer\n",
    "from tqdm.notebook import tqdm\n",
    "from sometimer import timer, time_this_method\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "sys.path.insert(0, '../ct')\n",
    "\n",
    "import load\n",
    "import preprocess\n",
    "# from preprocess import preprocess\n",
    "from preprocess import Tokenizer\n",
    "from preprocess.preprocess import separator_samples\n",
    "\n",
    "from model.layers import LayerNormalization\n",
    "from model.layers import ContentBasedAttention_CT\n",
    "from model.layers import ScaledDotProductAttention\n",
    "from model.layers import MultiHeadAttention\n",
    "from model.layers import content_based_attention\n",
    "\n",
    "from model import CompressiveTransformer\n",
    "from model import AttentionReconstruction\n",
    "\n",
    "from model.callbacks import ClearCompressedMemory, WriteLogsToFile\n",
    "from train.generators import next_token_batch_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compressive Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "vocab_size=16384\n",
    "lowercase=False\n",
    "language='english'\n",
    "train_val_split=0.8\n",
    "input_paths={'en': '../data/wma-en-de/input/train-en.txt',\n",
    "             'de': '../data/wma-en-de/input/train-de.txt'}\n",
    "tokenizer_output_path=f'../data/wma-en-de/tokenizer/' \\\n",
    "                      f'en-de-v0-t{vocab_size}{\"-lowercase\" if lowercase else \"\"}.tok'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=100\n",
    "batch_size=128\n",
    "d_layers=2\n",
    "sequence_length=128\n",
    "d_model=128\n",
    "train_steps=1200000\n",
    "validation_steps=10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wma = load.wma(input_paths['en'], \n",
    "               input_paths['de'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(input_paths=list(input_paths.values()),\n",
    "                      tokenizer_output_path=tokenizer_output_path,\n",
    "                      vocab_size=vocab_size,\n",
    "                      lowercase=lowercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, train, val = preprocess.wma(input_paths,\n",
    "                                  wma[[language]],\n",
    "                                  tokenizer_output_path,\n",
    "                                  train_val_split=train_val_split,\n",
    "                                  vocab_size=vocab_size,\n",
    "                                  language=language,\n",
    "                                  lowercase=lowercase,\n",
    "                                  tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_steps=train_steps or len(train)\n",
    "validation_steps=validation_steps or len(val)\n",
    "steps_per_epoch=epoch_steps//sequence_length - 1\n",
    "steps_per_validation=validation_steps//sequence_length - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = CompressiveTransformer(d_layers=d_layers,\n",
    "                            sequence_length=sequence_length, \n",
    "                            d_model=d_model,\n",
    "                            memory_size=256,\n",
    "                            compressed_memory_size=256,\n",
    "                            d_k=16, \n",
    "                            d_heads=2, \n",
    "                            output_size=vocab_size,\n",
    "                            batch_size=batch_size,\n",
    "                            vocab_size=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct.compile(optimizer='Adam',\n",
    "           loss='categorical_crossentropy',\n",
    "           metrics=['accuracy']\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CompressiveTransformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "x (InputLayer)                  (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "h_L0 (Embedding)                (None, 128, 128)     2097152     x[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "compressed_memory (InputLayer)  (None, 2, 256, 128)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "memory (InputLayer)             (None, 2, 256, 128)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_embedding (Dropout)     (None, 128, 128)     0           h_L0[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "select_compressed_memory_L0 (La (None, 256, 128)     0           compressed_memory[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "select_memory_L0 (Lambda)       (None, 256, 128)     0           memory[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "h_tilde_L0 (Concatenate)        (None, 640, 128)     0           select_compressed_memory_L0[0][0]\n",
      "                                                                 select_memory_L0[0][0]           \n",
      "                                                                 dropout_embedding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "scaled_dot_product_attention_1  (None, 128, 128)     20480       dropout_embedding[0][0]          \n",
      "                                                                 h_tilde_L0[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "scaled_dot_product_attention_2  (None, 128, 128)     20480       dropout_embedding[0][0]          \n",
      "                                                                 h_tilde_L0[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multihead_attention_L0 (MultiHe (None, 128, 128)     32768       scaled_dot_product_attention_1[0]\n",
      "                                                                 scaled_dot_product_attention_2[0]\n",
      "__________________________________________________________________________________________________\n",
      "mha_skip_L0 (Add)               (None, 128, 128)     0           dropout_embedding[0][0]          \n",
      "                                                                 multihead_attention_L0[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mha_layer_norm_L0 (LayerNormali (None, 128, 128)     32768       mha_skip_L0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "mlp_hidden_0_L0 (Dense)         (None, 128, 128)     16512       mha_layer_norm_L0[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "mlp_no_activation_L0 (Dense)    (None, 128, 128)     16512       mlp_hidden_0_L0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_L0 (Dropout)            (None, 128, 128)     0           mlp_no_activation_L0[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "mlp_skip_L0 (Add)               (None, 128, 128)     0           dropout_L0[0][0]                 \n",
      "                                                                 mha_layer_norm_L0[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "h_L1 (LayerNormalization)       (None, 128, 128)     32768       mlp_skip_L0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "select_compressed_memory_L1 (La (None, 256, 128)     0           compressed_memory[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "select_memory_L1 (Lambda)       (None, 256, 128)     0           memory[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "h_tilde_L1 (Concatenate)        (None, 640, 128)     0           select_compressed_memory_L1[0][0]\n",
      "                                                                 select_memory_L1[0][0]           \n",
      "                                                                 h_L1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "scaled_dot_product_attention_3  (None, 128, 128)     20480       h_L1[0][0]                       \n",
      "                                                                 h_tilde_L1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "scaled_dot_product_attention_4  (None, 128, 128)     20480       h_L1[0][0]                       \n",
      "                                                                 h_tilde_L1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multihead_attention_L1 (MultiHe (None, 128, 128)     32768       scaled_dot_product_attention_3[0]\n",
      "                                                                 scaled_dot_product_attention_4[0]\n",
      "__________________________________________________________________________________________________\n",
      "mha_skip_L1 (Add)               (None, 128, 128)     0           h_L1[0][0]                       \n",
      "                                                                 multihead_attention_L1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mha_layer_norm_L1 (LayerNormali (None, 128, 128)     32768       mha_skip_L1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "mlp_hidden_0_L1 (Dense)         (None, 128, 128)     16512       mha_layer_norm_L1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "mlp_no_activation_L1 (Dense)    (None, 128, 128)     16512       mlp_hidden_0_L1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_L1 (Dropout)            (None, 128, 128)     0           mlp_no_activation_L1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "mlp_skip_L1 (Add)               (None, 128, 128)     0           dropout_L1[0][0]                 \n",
      "                                                                 mha_layer_norm_L1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "h_L2 (LayerNormalization)       (None, 128, 128)     32768       mlp_skip_L1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "output (ReverseEmbedding)       (None, 16384)        2097152     h_L2[0][0]                       \n",
      "==================================================================================================\n",
      "Total params: 4,538,880\n",
      "Trainable params: 2,441,728\n",
      "Non-trainable params: 2,097,152\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ct.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train/test data-generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = next_token_batch_generator(ct=ct,\n",
    "                                       data=train,\n",
    "                                       data_path=None,\n",
    "                                       epoch_steps=epoch_steps, \n",
    "                                       sequence_length=sequence_length, \n",
    "                                       batch_size=sequence_length,\n",
    "                                       vocab_size=vocab_size)\n",
    "validation_generator = next_token_batch_generator(ct=ct, \n",
    "                                                  data=val,\n",
    "                                                  data_path=None,\n",
    "                                                  epoch_steps=validation_steps, \n",
    "                                                  sequence_length=sequence_length, \n",
    "                                                  batch_size=sequence_length,\n",
    "                                                  vocab_size=vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create addtional Run Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [ClearCompressedMemory(),\n",
    "             WriteLogsToFile(filepath='training-logs/ct.txt', overwrite_old_file=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vs/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5036/9374 [===============>..............] - ETA: 29:19 - loss: 7.2159 - accuracy: 0.0367"
     ]
    }
   ],
   "source": [
    "ct.fit_generator(generator(), \n",
    "                 steps_per_epoch=steps_per_epoch,\n",
    "                 epochs=epochs,\n",
    "                 callbacks=callbacks,\n",
    "                 validation_data=validation_generator(),\n",
    "                 validation_steps=steps_per_validation,\n",
    "                 shuffle=False\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- multiple layers\n",
    "- larger embedding\n",
    "- longer dataset\n",
    "- relative embedding\n",
    "- attention reconstruction loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
