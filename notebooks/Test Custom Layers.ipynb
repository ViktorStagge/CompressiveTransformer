{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from time import sleep\n",
    "from keras import backend as K\n",
    "from keras.models import Model \n",
    "from keras.models import Sequential as SequentialModel\n",
    "from keras.layers import Dense, Conv1D, LSTM, Dropout, Embedding, Layer, Input, Flatten, concatenate as Concatenate, Lambda\n",
    "from keras.callbacks import Callback\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer as KerasTokenizer\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "sys.path.insert(0, '../ct')\n",
    "\n",
    "import load\n",
    "from preprocess import preprocess\n",
    "from preprocess import Tokenizer\n",
    "from preprocess.preprocess import separator_samples\n",
    "\n",
    "from model.layers import LayerNormalization\n",
    "from model.layers import ContentBasedAttention_CT\n",
    "from model.layers import ScaledDotProductAttention\n",
    "from model.layers import MultiHeadAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_pickle('../data/processed/spooky-author/train.pkl')\n",
    "\n",
    "x_train = np.array(train_data.x.tolist())\n",
    "y_train = np.array(train_data.y.tolist())\n",
    "\n",
    "_x_train = np.zeros((x_train.shape[0], 128))  # samples, d_model\n",
    "_x_train[:,:x_train.shape[1]] = x_train\n",
    "x_train = _x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test output and input shape of a layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Custom Layer for understanding keras input-/output shapes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyLayer(LSTM):\n",
    "    def __init__(self, units, **kwargs):\n",
    "        super().__init__(units, **kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        print(f'build:   input_shape={input_shape}')\n",
    "        return super().build(input_shape)\n",
    "    \n",
    "    def call(self, x, **kwargs):\n",
    "        y = super().call(x, **kwargs)\n",
    "        print(f'call:    input_shape={x.shape}, output_shape={y.shape}')\n",
    "        sleep(1)\n",
    "        return y\n",
    "        \n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        output_shape = super().compute_output_shape(input_shape)\n",
    "        print(f'compute: input_shape={input_shape}, output_shape={output_shape}')\n",
    "        return output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = SequentialModel()\n",
    "    model.add(Embedding(input_dim=15000, output_dim=200))\n",
    "    model.add(LSTM(units=128, dropout=0.2, recurrent_dropout=0.15, return_sequences=True))\n",
    "    model.add(DummyLayer(units=200))\n",
    "    model.add(Dense(units=100))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='Adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build:   input_shape=(None, None, 128)\n",
      "call:    input_shape=(None, None, 128), output_shape=(None, 200)\n",
      "compute: input_shape=(None, None, 128), output_shape=(None, 200)\n"
     ]
    }
   ],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sgt-Peppers\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13705 samples, validate on 5874 samples\n",
      "Epoch 1/4\n",
      "13705/13705 [==============================] - 80s 6ms/step - loss: 0.9340 - accuracy: 0.5164 - val_loss: 0.7763 - val_accuracy: 0.5977\n",
      "Epoch 2/4\n",
      "13705/13705 [==============================] - 79s 6ms/step - loss: 0.6978 - accuracy: 0.6386 - val_loss: 0.7907 - val_accuracy: 0.6117\n",
      "Epoch 3/4\n",
      "13705/13705 [==============================] - 80s 6ms/step - loss: 0.5463 - accuracy: 0.7444 - val_loss: 0.6808 - val_accuracy: 0.7853\n",
      "Epoch 4/4\n",
      "13705/13705 [==============================] - 79s 6ms/step - loss: 0.3342 - accuracy: 0.8885 - val_loss: 0.5918 - val_accuracy: 0.8008\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1668c0bcf98>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, \n",
    "          y_train,\n",
    "          epochs=4,\n",
    "          batch_size=32,\n",
    "          validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expected Input/Output:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# LSTM-output as input\n",
    "build:   input_shape=(None, None, 128)\n",
    "call:    input_shape=(None, None, 128), output_shape=(None, 200)\n",
    "compute: input_shape=(None, None, 128), output_shape=(None, 200)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Layers included in model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = SequentialModel()\n",
    "    model.add(Embedding(input_dim=15000, output_dim=200))\n",
    "    model.add(LSTM(units=128, dropout=0.2, recurrent_dropout=0.15, return_sequences=False))\n",
    "    model.add(Dense(units=100))\n",
    "    model.add(LayerNormalization(units=100))\n",
    "    # model.add(Dense(units=100))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='Adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(x_train, \n",
    "          y_train,\n",
    "          epochs=8,\n",
    "          batch_size=32,\n",
    "          validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_22 (Embedding)     (None, None, 200)         3000000   \n",
      "_________________________________________________________________\n",
      "lstm_27 (LSTM)               (None, 128)               168448    \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 100)               12900     \n",
      "_________________________________________________________________\n",
      "layer_normalization_5 (Layer (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 3,181,651\n",
      "Trainable params: 3,181,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaled Dot Product Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### INIT <class 'model.layers.attention.ScaledDotProductAttention'> ####\n",
      "#### BUILD <class 'model.layers.attention.ScaledDotProductAttention'> ####\n",
      "#### CALL <class 'model.layers.attention.ScaledDotProductAttention'> ####\n",
      "    q=(None, None, 16),\n",
      "    k=(None, None, 16),\n",
      "    v=(None, None, 128)\n",
      "    k_T=(None, 16, None)\n",
      "    y=(None, None, 128)\n",
      "#### COMPUTE OUTPUT SHAPE ####\n",
      "(None, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    # x = Input()\n",
    "    model = SequentialModel()\n",
    "    model.add(Embedding(input_dim=15000, output_dim=128))\n",
    "    # model.add(LSTM(units=128, dropout=0.2, recurrent_dropout=0.15, return_sequences=True))\n",
    "    model.add(ScaledDotProductAttention(d_model=128, d_k=16, d_v=128))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=100, name='hidden_0'))\n",
    "    model.add(LayerNormalization(units=100))\n",
    "    model.add(Dense(3, activation='softmax', name='output_layer'))\n",
    "\n",
    "    model.compile(optimizer='Adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 128)         1920000   \n",
      "_________________________________________________________________\n",
      "scaled_dot_product_attention (None, 128, 128)          20480     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "hidden_0 (Dense)             (None, 100)               1638500   \n",
      "_________________________________________________________________\n",
      "layer_normalization_1 (Layer (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 3,579,283\n",
      "Trainable params: 3,579,283\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sgt-Peppers\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13705 samples, validate on 5874 samples\n",
      "Epoch 1/8\n",
      "13705/13705 [==============================] - 36s 3ms/step - loss: 1.0920 - accuracy: 0.3945 - val_loss: 1.0781 - val_accuracy: 0.4052\n",
      "Epoch 2/8\n",
      "13705/13705 [==============================] - 35s 3ms/step - loss: 0.8632 - accuracy: 0.6027 - val_loss: 0.5728 - val_accuracy: 0.7606\n",
      "Epoch 3/8\n",
      "13705/13705 [==============================] - 33s 2ms/step - loss: 0.4080 - accuracy: 0.8550 - val_loss: 0.4429 - val_accuracy: 0.8299\n",
      "Epoch 4/8\n",
      "13705/13705 [==============================] - 33s 2ms/step - loss: 0.2532 - accuracy: 0.9225 - val_loss: 0.4647 - val_accuracy: 0.8190\n",
      "Epoch 5/8\n",
      "13705/13705 [==============================] - 35s 3ms/step - loss: 0.1738 - accuracy: 0.9527 - val_loss: 0.4680 - val_accuracy: 0.8177\n",
      "Epoch 6/8\n",
      "13705/13705 [==============================] - 35s 3ms/step - loss: 0.1184 - accuracy: 0.9721 - val_loss: 0.5073 - val_accuracy: 0.8100\n",
      "Epoch 7/8\n",
      "13705/13705 [==============================] - 35s 3ms/step - loss: 0.0855 - accuracy: 0.9804 - val_loss: 0.5577 - val_accuracy: 0.8035\n",
      "Epoch 8/8\n",
      "13705/13705 [==============================] - 34s 2ms/step - loss: 0.0655 - accuracy: 0.9853 - val_loss: 0.6253 - val_accuracy: 0.7874\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x25871ae27f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, \n",
    "          y_train,\n",
    "          epochs=8,\n",
    "          batch_size=32,\n",
    "          validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### INIT [ScaledDotProductAttention] ####\n",
      "#### BUILD [ScaledDotProductAttention] ####\n",
      "#### CALL [ScaledDotProductAttention] ####\n",
      "    q=(None, 128, 16),\n",
      "    k=(None, 128, 16),\n",
      "    v=(None, 128, 128)\n",
      "    k_T=(None, 16, 128)\n",
      "    y=(None, 128, 128)\n",
      "#### COMPUTE OUTPUT SHAPE ####\n",
      "(None, 128, 128)\n",
      "#### INIT [ScaledDotProductAttention] ####\n",
      "#### BUILD [ScaledDotProductAttention] ####\n",
      "#### CALL [ScaledDotProductAttention] ####\n",
      "    q=(None, 128, 16),\n",
      "    k=(None, 128, 16),\n",
      "    v=(None, 128, 128)\n",
      "    k_T=(None, 16, 128)\n",
      "    y=(None, 128, 128)\n",
      "#### COMPUTE OUTPUT SHAPE ####\n",
      "(None, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "def get_model(number_of_heads=2):\n",
    "    input_layer = Input(shape=(128,))\n",
    "\n",
    "    _0_x = Embedding(input_dim=15000, output_dim=128)(input_layer)\n",
    "\n",
    "    _1_s = [ScaledDotProductAttention(d_model=128, d_k=16, d_v=128)(_0_x) for _ in range(number_of_heads)]\n",
    "    _1_m = MultiHeadAttention(d_heads=2, d_model=128, d_k=16, d_v=128)(_1_s)\n",
    "\n",
    "    _2_f = Flatten()(_1_m)\n",
    "    _2_h_0 = Dense(units=10, name='hidden_0')(_2_f)\n",
    "    _2_hL_0 = LayerNormalization(units=10)(_2_h_0)\n",
    "\n",
    "    output_layer = Dense(3, activation='softmax', name='output_layer')(_2_hL_0)\n",
    "\n",
    "    model = Model(inputs=[input_layer],\n",
    "                  outputs=[output_layer])\n",
    "    model.compile(optimizer='Adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_13 (Embedding)        (None, 128, 128)     1920000     input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "scaled_dot_product_attention_20 (None, 128, 128)     20480       embedding_13[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "scaled_dot_product_attention_21 (None, 128, 128)     20480       embedding_13[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_8 (MultiHe (None, 128, 128)     32768       scaled_dot_product_attention_20[0\n",
      "                                                                 scaled_dot_product_attention_21[0\n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 16384)        0           multi_head_attention_8[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "hidden_0 (Dense)                (None, 10)           163850      flatten_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_5 (LayerNor (None, 10)           0           hidden_0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 3)            33          layer_normalization_5[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 2,157,611\n",
      "Trainable params: 2,157,611\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sgt-Peppers\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13705 samples, validate on 5874 samples\n",
      "Epoch 1/8\n",
      "13705/13705 [==============================] - 40s 3ms/step - loss: 1.1636 - accuracy: 0.4026 - val_loss: 1.0867 - val_accuracy: 0.4048\n",
      "Epoch 2/8\n",
      "13705/13705 [==============================] - 42s 3ms/step - loss: 0.9443 - accuracy: 0.5229 - val_loss: 0.8525 - val_accuracy: 0.6038\n",
      "Epoch 3/8\n",
      "13705/13705 [==============================] - 46s 3ms/step - loss: 0.7807 - accuracy: 0.6676 - val_loss: 0.8124 - val_accuracy: 0.6136\n",
      "Epoch 4/8\n",
      "13705/13705 [==============================] - 41s 3ms/step - loss: 0.6962 - accuracy: 0.7502 - val_loss: 0.7403 - val_accuracy: 0.7484\n",
      "Epoch 5/8\n",
      "13705/13705 [==============================] - 42s 3ms/step - loss: 0.5858 - accuracy: 0.8787 - val_loss: 0.6736 - val_accuracy: 0.7804\n",
      "Epoch 6/8\n",
      "13705/13705 [==============================] - 41s 3ms/step - loss: 0.4828 - accuracy: 0.9317 - val_loss: 0.6069 - val_accuracy: 0.8109\n",
      "Epoch 7/8\n",
      "13705/13705 [==============================] - 41s 3ms/step - loss: 0.3907 - accuracy: 0.9562 - val_loss: 0.5786 - val_accuracy: 0.8035\n",
      "Epoch 8/8\n",
      "13705/13705 [==============================] - 40s 3ms/step - loss: 0.3113 - accuracy: 0.9693 - val_loss: 0.5563 - val_accuracy: 0.8059\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2580641ac18>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, \n",
    "          y_train,\n",
    "          epochs=8,\n",
    "          batch_size=32,\n",
    "          validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subclassing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### INIT [ScaledDotProductAttention] ####\n",
      "#### BUILD [ScaledDotProductAttention] ####\n",
      "#### CALL [ScaledDotProductAttention] ####\n",
      "    q=(None, 128, 16),\n",
      "    k=(None, 128, 16),\n",
      "    v=(None, 128, 128)\n",
      "    k_T=(None, 16, 128)\n",
      "    y=(None, 128, 128)\n",
      "#### COMPUTE OUTPUT SHAPE ####\n",
      "(None, 128, 128)\n",
      "#### INIT [ScaledDotProductAttention] ####\n",
      "#### BUILD [ScaledDotProductAttention] ####\n",
      "#### CALL [ScaledDotProductAttention] ####\n",
      "    q=(None, 128, 16),\n",
      "    k=(None, 128, 16),\n",
      "    v=(None, 128, 128)\n",
      "    k_T=(None, 16, 128)\n",
      "    y=(None, 128, 128)\n",
      "#### COMPUTE OUTPUT SHAPE ####\n",
      "(None, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "class MHAModel(Model):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        input_layer = Input(shape=(128,))\n",
    "\n",
    "        _0_x = Embedding(input_dim=15000, output_dim=128)(input_layer)\n",
    "\n",
    "        _1_s = [ScaledDotProductAttention(d_model=128, d_k=16, d_v=128)(_0_x) for _ in range(2)]\n",
    "        _1_m = MultiHeadAttention(d_heads=2, d_model=128, d_k=16, d_v=128)(_1_s)\n",
    "\n",
    "        _2_f = Flatten()(_1_m)\n",
    "        _2_h_0 = Dense(units=10, name='hidden_0')(_2_f)\n",
    "        _2_hL_0 = LayerNormalization(units=10)(_2_h_0)\n",
    "        \n",
    "        output_layer = Dense(3, activation='softmax', name='output_layer')(_2_hL_0)\n",
    "    \n",
    "        super().__init__(inputs=[input_layer], \n",
    "                         outputs=[output_layer], \n",
    "                         *args, \n",
    "                         **kwargs)\n",
    "\n",
    "def get_model():\n",
    "    model = MHAModel(name='Easy keras, EASY.')\n",
    "    return model\n",
    "\n",
    "\n",
    "model = get_model()\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Easy keras, EASY.\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 128, 128)     1920000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "scaled_dot_product_attention_1  (None, 128, 128)     20480       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "scaled_dot_product_attention_2  (None, 128, 128)     20480       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_1 (MultiHe (None, 128, 128)     32768       scaled_dot_product_attention_1[0]\n",
      "                                                                 scaled_dot_product_attention_2[0]\n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 16384)        0           multi_head_attention_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "hidden_0 (Dense)                (None, 10)           163850      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_1 (LayerNor (None, 10)           0           hidden_0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 3)            33          layer_normalization_1[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 2,157,611\n",
      "Trainable params: 2,157,611\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model within a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### INIT [ScaledDotProductAttention] ####\n",
      "#### INIT [ScaledDotProductAttention] ####\n",
      "#### BUILD [ScaledDotProductAttention] ####\n",
      "#### CALL [ScaledDotProductAttention] ####\n",
      "    q=(None, 128, 16),\n",
      "    k=(None, 128, 16),\n",
      "    v=(None, 128, 128)\n",
      "    k_T=(None, 16, 128)\n",
      "    y=(None, 128, 128)\n",
      "#### COMPUTE OUTPUT SHAPE ####\n",
      "(None, 128, 128)\n",
      "#### BUILD [ScaledDotProductAttention] ####\n",
      "#### CALL [ScaledDotProductAttention] ####\n",
      "    q=(None, 128, 16),\n",
      "    k=(None, 128, 16),\n",
      "    v=(None, 128, 128)\n",
      "    k_T=(None, 16, 128)\n",
      "    y=(None, 128, 128)\n",
      "#### COMPUTE OUTPUT SHAPE ####\n",
      "(None, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "class ModelCeption(Model):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        \n",
    "        # Model\n",
    "        input_layer = Input(shape=(128,))\n",
    "\n",
    "        _0_x = Embedding(input_dim=15000, output_dim=128)\n",
    "\n",
    "        _1_s = [ScaledDotProductAttention(d_model=128, d_k=16, d_v=128) for _ in range(2)]\n",
    "        _1_m = MultiHeadAttention(d_heads=2, d_model=128, d_k=16, d_v=128)\n",
    "\n",
    "        _2_f = Flatten()\n",
    "        _2_h_0 = Dense(units=10, name='hidden_0')\n",
    "        _2_hL_0 = LayerNormalization(units=10)\n",
    "        \n",
    "        output_layer = Dense(3, activation='softmax', name='output_layer')\n",
    "    \n",
    "        \n",
    "        _0_x_tensor = _0_x(input_layer)\n",
    "        _1_s_tensor = [head(_0_x_tensor) for head in _1_s]\n",
    "        _1_m_tensor = _1_m(_1_s_tensor)\n",
    "        _2_f_tensor = _2_f(_1_m_tensor)\n",
    "        _2_h_0_tensor = _2_h_0(_2_f_tensor)\n",
    "        _2_hL_0_tensor = _2_hL_0(_2_h_0_tensor)\n",
    "        output_tensor = output_layer(_2_hL_0_tensor)\n",
    "    \n",
    "        super().__init__(inputs=input_layer,\n",
    "                         outputs=output_tensor,\n",
    "                         *args, \n",
    "                         **kwargs)\n",
    "        self.inner_model = {'inner_model': InnerModel(),\n",
    "                            'inner_model_input': _2_f}\n",
    "        self.input_layer = input_layer\n",
    "        self._0_x = _0_x\n",
    "        self._1_s = _1_s\n",
    "        self._1_m = _1_m\n",
    "        self._2_f = _2_f\n",
    "        self._2_h_0 = _2_h_0\n",
    "        self._2_hL_0 = _2_hL_0\n",
    "        self.output_layer = output_layer\n",
    "        \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        print('CALLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLL')\n",
    "        super().__call__(*args, **kwargs)\n",
    "        \n",
    "#     def fit():\n",
    "#         pass\n",
    "\n",
    "#     def train_on_batch:\n",
    "#         pass\n",
    "    \n",
    "    def call(self, inputs, *args, **kwargs):\n",
    "        print()\n",
    "        print('INPUTS')\n",
    "        print(inputs)\n",
    "        # sleep(2)\n",
    "        exit(-1)\n",
    "        super().call(inputs, *args, **kwargs)\n",
    "    \n",
    "    def compile(self, *args, **kwargs):\n",
    "        super().compile(*args, **kwargs)\n",
    "        self.inner_model['inner_model'].compile(optimizer='Adam',\n",
    "                                                loss='categorical_crossentropy',\n",
    "                                                metrics=['accuracy'])\n",
    "\n",
    "\n",
    "class InnerModel(Model):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        _inputs = Input((16384,))\n",
    "        # z = Lambda(lambda x: K.stop_gradient(x))(_inputs)\n",
    "        z = Dense(units=10, name='inner_0')(_inputs)\n",
    "        z = LayerNormalization(units=10)(z)\n",
    "        \n",
    "        output_layer = Dense(3, activation='softmax', name='inner_output')(z)\n",
    "        \n",
    "        super().__init__(*args,\n",
    "                         inputs=_inputs,\n",
    "                         outputs=output_layer,\n",
    "                         **kwargs)\n",
    "\n",
    "class TrainInnerModelCallback(Callback):\n",
    "    def __init__(self, inner_model, pseudo_input,*args, **kwags):\n",
    "        self.inner_model = inner_model\n",
    "        self.pseudo_input = pseudo_input\n",
    "        super().__init__()\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        print()\n",
    "        print(self.pseudo_input.output)\n",
    "        sleep(2)\n",
    "        \n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "        \n",
    "def get_model():\n",
    "    model = ModelCeption(name='ModelCeption')\n",
    "    return model\n",
    "\n",
    "\n",
    "model = get_model()\n",
    "model.compile(optimizer='Adam',\n",
    "              loss=['categorical_crossentropy'],\n",
    "              metrics=['accuracy']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ModelCeption\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_86 (InputLayer)           (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_50 (Embedding)        (None, 128, 128)     1920000     input_86[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "scaled_dot_product_attention_99 (None, 128, 128)     20480       embedding_50[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "scaled_dot_product_attention_10 (None, 128, 128)     20480       embedding_50[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_50 (MultiH (None, 128, 128)     32768       scaled_dot_product_attention_99[0\n",
      "                                                                 scaled_dot_product_attention_100[\n",
      "__________________________________________________________________________________________________\n",
      "flatten_50 (Flatten)            (None, 16384)        0           multi_head_attention_50[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "hidden_0 (Dense)                (None, 10)           163850      flatten_50[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_81 (LayerNo (None, 10)           0           hidden_0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 3)            33          layer_normalization_81[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 2,157,611\n",
      "Trainable params: 2,157,611\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "callback = TrainInnerModelCallback(inner_model=model.inner_model['inner_model'], \n",
    "                                   pseudo_input=model._2_f)\n",
    "\n",
    "model.fit(x_train, \n",
    "          y_train,\n",
    "          epochs=8,\n",
    "          batch_size=32,\n",
    "          validation_split=0.3,\n",
    "          callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.backend.EagerExecutionFunction at 0x2b20ba7d208>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "epoch: 3\n",
      "epoch: 4\n"
     ]
    }
   ],
   "source": [
    "x_t = x_train[:int(0.7*len(x_train))]\n",
    "y_t = y_train[:int(0.7*len(x_train))]\n",
    "\n",
    "x_v = x_train[int(0.7*len(x_train)):]\n",
    "y_v = y_train[int(0.7*len(x_train)):]\n",
    "\n",
    "output = []\n",
    "for e in range(5):\n",
    "    print(f'epoch: {e}')\n",
    "    epoch_output = []\n",
    "    for i in range(0, len(x_t), 16):\n",
    "        batch_output = model.train_on_batch(x_t[i: i+16], y_t[i: i+16])\n",
    "        epoch_output.append(batch_output)\n",
    "    output.append(epoch_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5874/5874 [==============================] - 4s 640us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5742112807868077, 0.7788559794425964]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_v, y_v, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### INIT [ScaledDotProductAttention] ####\n",
      "#### BUILD [ScaledDotProductAttention] ####\n",
      "#### CALL [ScaledDotProductAttention] ####\n",
      "    q=(None, 128, 16),\n",
      "    k=(None, 128, 16),\n",
      "    v=(None, 128, 128)\n",
      "    k_T=(None, 16, 128)\n",
      "    y=(None, 128, 128)\n",
      "#### COMPUTE OUTPUT SHAPE ####\n",
      "(None, 128, 128)\n",
      "#### INIT [ScaledDotProductAttention] ####\n",
      "#### BUILD [ScaledDotProductAttention] ####\n",
      "#### CALL [ScaledDotProductAttention] ####\n",
      "    q=(None, 128, 16),\n",
      "    k=(None, 128, 16),\n",
      "    v=(None, 128, 128)\n",
      "    k_T=(None, 16, 128)\n",
      "    y=(None, 128, 128)\n",
      "#### COMPUTE OUTPUT SHAPE ####\n",
      "(None, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(shape=(128,))\n",
    "_0_x = Embedding(input_dim=15000, output_dim=128)(input_layer)\n",
    "_1_s = [ScaledDotProductAttention(d_model=128, d_k=16, d_v=128)(_0_x) for _ in range(2)]\n",
    "_1_m = MultiHeadAttention(d_heads=2, d_model=128, d_k=16, d_v=128)(_1_s)\n",
    "_2_f = Flatten(name='flattened_intermediate_layer')(_1_m)\n",
    "_2_h_0 = Dense(units=10, name='hidden_0')(_2_f)\n",
    "_2_hL_0 = LayerNormalization(units=10)(_2_h_0)\n",
    "output_layer = Dense(3, activation='softmax', name='output_layer')(_2_hL_0)\n",
    "\n",
    "model = Model(inputs=[input_layer], outputs=[output_layer])\n",
    "\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = x_train[:16]\n",
    "batch_labels = y_train[:16]\n",
    "\n",
    "flatten_output_function = K.function([model.input], _2_f)\n",
    "flatten_output = flatten_output_function(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00475288,  0.00809301,  0.00449178, ...,  0.00615292,\n",
       "        -0.00346607,  0.00294867],\n",
       "       [ 0.00431834,  0.00817334,  0.00445237, ...,  0.00606779,\n",
       "        -0.00345981,  0.00317416],\n",
       "       [ 0.00489997,  0.00777089,  0.00452916, ...,  0.00555791,\n",
       "        -0.00330961,  0.00295466],\n",
       "       ...,\n",
       "       [ 0.00379726,  0.00619949,  0.0033668 , ...,  0.00474489,\n",
       "        -0.0024537 ,  0.00245047],\n",
       "       [ 0.00449217,  0.00723123,  0.00419872, ...,  0.00574301,\n",
       "        -0.00319548,  0.00289049],\n",
       "       [ 0.00438056,  0.00737246,  0.00391611, ...,  0.00511611,\n",
       "        -0.00302   ,  0.00243112]], dtype=float32)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 16384)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner = InnerModel()\n",
    "inner.compile(optimizer='Adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.5845277, 0.1875]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inner.train_on_batch(x=flatten_output,\n",
    "                     y=batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### INIT [ScaledDotProductAttention] ####\n",
      "#### INIT [ScaledDotProductAttention] ####\n",
      "#### BUILD [ScaledDotProductAttention] ####\n",
      "#### CALL [ScaledDotProductAttention] ####\n",
      "    q=(None, 128, 16),\n",
      "    k=(None, 128, 16),\n",
      "    v=(None, 128, 128)\n",
      "    k_T=(None, 16, 128)\n",
      "    y=(None, 128, 128)\n",
      "#### COMPUTE OUTPUT SHAPE ####\n",
      "(None, 128, 128)\n",
      "#### BUILD [ScaledDotProductAttention] ####\n",
      "#### CALL [ScaledDotProductAttention] ####\n",
      "    q=(None, 128, 16),\n",
      "    k=(None, 128, 16),\n",
      "    v=(None, 128, 128)\n",
      "    k_T=(None, 16, 128)\n",
      "    y=(None, 128, 128)\n",
      "#### COMPUTE OUTPUT SHAPE ####\n",
      "(None, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "input_layer = Input(shape=(128,))\n",
    "_0_x = Embedding(input_dim=15000, output_dim=128)\n",
    "_1_s = [ScaledDotProductAttention(d_model=128, d_k=16, d_v=128) for _ in range(2)]\n",
    "_1_m = MultiHeadAttention(d_heads=2, d_model=128, d_k=16, d_v=128)\n",
    "_2_f = Flatten()\n",
    "_2_h_0 = Dense(units=10, name='hidden_0')\n",
    "_2_hL_0 = LayerNormalization(units=10)\n",
    "output_layer = Dense(3, activation='softmax', name='output_layer')\n",
    "\n",
    "_0_x_tensor = _0_x(input_layer)\n",
    "_1_s_tensor = [head(_0_x_tensor) for head in _1_s]\n",
    "_1_m_tensor = _1_m(_1_s_tensor)\n",
    "_2_f_tensor = _2_f(_1_m_tensor)\n",
    "_2_h_0_tensor = _2_h_0(_2_f_tensor)\n",
    "_2_hL_0_tensor = _2_hL_0(_2_h_0_tensor)\n",
    "output_tensor = output_layer(_2_hL_0_tensor)\n",
    "\n",
    "model = Model(inputs=[input_layer], outputs=[output_tensor])\n",
    "\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'flatten_60/Reshape:0' shape=(None, None) dtype=float32>"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_2_f.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'flatten_60/Reshape:0' shape=(None, None) dtype=float32>"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_2_f_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class test_model(Model):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        \n",
    "        inp1 = Input(shape=(10,))\n",
    "        inp2 = Input(shape=(10,))\n",
    "        \n",
    "        x = Concatenate(inputs=[inp1, inp2], axis=1)\n",
    "        z = Dense(10)(x)\n",
    "        \n",
    "        y = Dense(3, activation='softmax')(z)\n",
    "        \n",
    "        super().__init__(inputs=[inp1, inp2], outputs=[x], *args, **kwargs)\n",
    "        \n",
    "    def train_on_batch(self, x, y, *args,**kwargs):\n",
    "        print(x)\n",
    "        inp1, inp2 = x\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        super().train_on_batch(x, y, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 20)           0           input_8[0][0]                    \n",
      "                                                                 input_9[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'Variable:0' shape=(16, 10) dtype=float32, numpy=\n",
      "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>, <tf.Variable 'Variable:0' shape=(16, 10) dtype=float32, numpy=\n",
      "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "m.train_on_batch(x=[K.zeros((16,10)), K.zeros((16, 10))],\n",
    "                 y=K.zeros((16, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33347207, 0.33337963, 0.33314833],\n",
       "       [0.33347207, 0.33337963, 0.33314833],\n",
       "       [0.33347207, 0.33337963, 0.33314833],\n",
       "       [0.33347207, 0.33337963, 0.33314833],\n",
       "       [0.33347207, 0.33337963, 0.33314833],\n",
       "       [0.33347207, 0.33337963, 0.33314833],\n",
       "       [0.33347207, 0.33337963, 0.33314833],\n",
       "       [0.33347207, 0.33337963, 0.33314833],\n",
       "       [0.33347207, 0.33337963, 0.33314833],\n",
       "       [0.33347207, 0.33337963, 0.33314833],\n",
       "       [0.33347207, 0.33337963, 0.33314833],\n",
       "       [0.33347207, 0.33337963, 0.33314833],\n",
       "       [0.33347207, 0.33337963, 0.33314833],\n",
       "       [0.33347207, 0.33337963, 0.33314833],\n",
       "       [0.33347207, 0.33337963, 0.33314833],\n",
       "       [0.33347207, 0.33337963, 0.33314833]], dtype=float32)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.eval(m([K.zeros((16,10)), K.zeros((16, 10))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
